{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 线性模型使用的代价函数\n",
    "![线性模型代价函数1](image/cross-entropy1.png)\n",
    "![线性模型代价函数2](image/cross-entropy2.png)\n",
    "### tensorflow中的线性模型代价函数写法(二次代价)\n",
    "`loss = tf.reduce_mean(tf.square(y - prediction))`\n",
    "- 这里的y是实际值(标签),prediction是输出的预测值\n",
    "\n",
    "# S型输出函数的代价函数-交叉熵\n",
    "![交叉熵代价函数1](image/cross-entropy1.png)\n",
    "![交叉熵代价函数2](image/cross-entropy2.png)\n",
    "### tensorflow中的S型输出函数的交叉熵代价函数的写法\n",
    "`loss = tf.nn.sigmoid_cross_entropy_with_logits()`\n",
    "\n",
    "# softmax输出的代价函数-对数似然\n",
    "![对数似然代价函数1](image/log-likelihood-cost.png)\n",
    "### tensorflow中的softmax输出函数的交叉熵代价函数(对数似然函数)的写法\n",
    "`loss = tf.nn.softmax_cross_entropy_with_logits()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 采用对数似然函数来改进class3中的手写体识别的线性分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /Users/yuejinxiong/MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting /Users/yuejinxiong/MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting /Users/yuejinxiong/MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /Users/yuejinxiong/MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "第1次迭代的准确率: 0.8251\n",
      "第2次迭代的准确率: 0.8941\n",
      "第3次迭代的准确率: 0.9028\n",
      "第4次迭代的准确率: 0.9052\n",
      "第5次迭代的准确率: 0.9083\n",
      "第6次迭代的准确率: 0.9103\n",
      "第7次迭代的准确率: 0.912\n",
      "第8次迭代的准确率: 0.9141\n",
      "第9次迭代的准确率: 0.9147\n",
      "第10次迭代的准确率: 0.917\n",
      "第11次迭代的准确率: 0.9173\n",
      "第12次迭代的准确率: 0.918\n",
      "第13次迭代的准确率: 0.9184\n",
      "第14次迭代的准确率: 0.9191\n",
      "第15次迭代的准确率: 0.9208\n",
      "第16次迭代的准确率: 0.9199\n",
      "第17次迭代的准确率: 0.9211\n",
      "第18次迭代的准确率: 0.9217\n",
      "第19次迭代的准确率: 0.9206\n",
      "第20次迭代的准确率: 0.9218\n",
      "第21次迭代的准确率: 0.9219\n"
     ]
    }
   ],
   "source": [
    "# 手写数字识别案例(线性分类器)\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "# 载入数据集。第一个参数是路径名，第二个是采用的编码\n",
    "mnist = input_data.read_data_sets(\"/Users/yuejinxiong/MNIST_data\",one_hot=True)\n",
    "\n",
    "# 每个批次的大小(每次放入100张图片去训练)\n",
    "batch_size = 100\n",
    "# 计算一共有多少个批次\n",
    "n_batch = mnist.train.num_examples // batch_size\n",
    "\n",
    "# 定义两个placeholder\n",
    "x = tf.placeholder(tf.float32, [None,784])\n",
    "y = tf.placeholder(tf.float32, [None,10])\n",
    "\n",
    "# 创建一个简单的神经网络--只有输入和输出层，没有隐藏层（改进后增加隐藏层）\n",
    "W = tf.Variable(tf.zeros([784, 10]))\n",
    "b = tf.Variable(tf.zeros([10]))\n",
    "prediction = tf.nn.softmax(tf.matmul(x, W)+b)\n",
    "\n",
    "# 增加了隐藏层之后,参数变多了,更加难以收敛,如果想得到好的结果,必须要迭代很多次\n",
    "# 隐藏层的神经元个数最好是2^n个\n",
    "\n",
    "# 输入层与隐藏层之间的权重和偏置的初始化 隐藏层有5个神经元\n",
    "# Weight_L1 = tf.Variable(tf.random_normal([784, 512]))\n",
    "# biases_L1 = tf.Variable(tf.zeros([1, 512]))\n",
    "# Wx_plus_b_L1 = tf.matmul(x, Weight_L1) + biases_L1\n",
    "# L1 = tf.nn.tanh(Wx_plus_b_L1)\n",
    "\n",
    "# 隐藏层和输出层之间权重和偏置的初始化\n",
    "# Weight_L2 = tf.Variable(tf.random_normal([512, 10]))\n",
    "# biases_L2 = tf.Variable(tf.zeros([1, 10]))\n",
    "# Wx_plus_b_L2 = tf.matmul(L1, Weight_L2) + biases_L2\n",
    "# prediction = tf.nn.softmax(Wx_plus_b_L2)\n",
    "\n",
    "# 二次代价函数\n",
    "# loss = tf.reduce_mean(tf.square(y-prediction))\n",
    "# 现在改为对数似然函数来优化\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=y, logits=prediction))\n",
    "# 梯度下降\n",
    "train_step = tf.train.GradientDescentOptimizer(0.2).minimize(loss)\n",
    "\n",
    "# 初始化变量\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# 这里求预测的正确数、结果存在一个布尔型的列表中\n",
    "# equal(num1, num2)比较两个参数的大小是否一样,返回值为True或False\n",
    "# arg_max() 求y(一维张量)这个结果最大的值的索引位置(如果标签值和预测值最大的值在同一个位置，则说明该条正确) 1表示按行查找\n",
    "correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(prediction, 1))\n",
    "\n",
    "# 求准确率, cast()将布尔类型的列表中的元素转成32位的浮点类型,然后再求一个平均值(true=1.0 false=0)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    # 所有数据迭代21次\n",
    "    for epoch in range(21):\n",
    "        # 一次迭代中迭代计算好的数量个批次\n",
    "        for batch in range(n_batch):\n",
    "            # 获取100个批次保存在里面,数据保存在batch_xs中，标签保存在batchys中\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "            sess.run(train_step, feed_dict={x:batch_xs, y:batch_ys})\n",
    "        # 训练一个周期后,可以查看其准确率的变化\n",
    "        acc = sess.run(accuracy, feed_dict={x:mnist.test.images, y:mnist.test.labels})\n",
    "        print(\"第\"+str(epoch+1)+\"次迭代的准确率: \"+str(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3-7for learn",
   "language": "python",
   "name": "py3-7forlearn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
