{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 传统神经网络存在的问题\n",
    "- 权值太多，计算量太大\n",
    "- 权值大多，需要大量样本进行训练（经验来讲，一般样本的数量要是待训练的权值数量的5-30倍）\n",
    "![class9_1](image/class9_1.png)\n",
    "\n",
    "# 卷积神经网络CNN\n",
    "- CNN通过感受野和权值共享减少了神经网络需要训练的参数个数\n",
    "![class9_2](image/class9_2.png)\n",
    "\n",
    "## 卷积操作\n",
    "- 这里的卷积核大小是3X3，步长是1\n",
    "![class9_3](image/class9_3.png)\n",
    "\n",
    "## 几种不同的卷积核\n",
    "- 其实卷积核可以视为是一种滤波器，下面就是两种不同的卷积核过滤同一张图片的结果\n",
    "- 下面一张个图片经过不同的卷积核形成了两种不同的特征图\n",
    "- 所以，不同的卷积核可以对不同的特征进行采样\n",
    "![class9_4](image/class9_4.png)\n",
    "\n",
    "## 对于卷积的一些优化\n",
    "- Same Padding: 给平面外部补0，卷积窗口采样后得到一个跟原来平面大小相同的平面（步长设置为1）\n",
    "- Valid Padding: 不会超出平面外部，卷积窗口采样后得到一个比原来小的平面\n",
    "![class9_6](image/class9_6.png)\n",
    "\n",
    "## 池化操作\n",
    "- 池化操作跟卷积操作非常类似，主要用于降维，缩小特征图\n",
    "- 池化操作一般分为最大值池化(max-pooling)和平均值池化(mean-pooling)，还有随机值池化\n",
    "![class9_5](image/class9_5.png)\n",
    "\n",
    "## 对于池化的一些优化\n",
    "- Same padding: 可能会给平面外部补0\n",
    "- Valid padding: 不会超出平面外部\n",
    "\n",
    "##### 假如有一个28*28的平面，用2*2且步长为2的窗口对其进行pooling操作\n",
    "- 使用Same padding的方式，得到的是一个14*14的平面\n",
    "- 使用Valid padding的方式，得到的也是14*14的平面\n",
    "\n",
    "##### 假如有一个2*3的平面，用2*2且步长为2的窗口对其进行pooling操作\n",
    "- 使用Same padding的方式，得到的是一个1*2的平面\n",
    "- 使用Valid padding的方式，得到的也是1*1的平面\n",
    "\n",
    "# CNN的结构\n",
    "#### 下图就是先经过一个卷积层和池化层得到128X128X16再经过一个卷积层和池化层得到64X64X64再经过一个卷积层和池化层得到32X32X256，最后连接一个全连接层去做分类\n",
    "![class9_7](image/class9_7.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /Users/yuejinxiong/MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting /Users/yuejinxiong/MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting /Users/yuejinxiong/MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /Users/yuejinxiong/MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From <ipython-input-5-7f8eea12aa4e>:92: arg_max (from tensorflow.python.ops.gen_math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `argmax` instead\n"
     ]
    }
   ],
   "source": [
    "# CNN案例\n",
    "mnist = input_data.read_data_sets('/Users/yuejinxiong/MNIST_data', one_hot=True)\n",
    "# 每个训练批次的大小\n",
    "batch_size = 100\n",
    "# 计算一共有多少个批次（训练集）\n",
    "n_batch = mnist.train.num_examples // batch_size\n",
    "\n",
    "# 初始化权值\n",
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)  # 生成一个标准差为0.1的截断的正态分布随机矩阵\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "# 初始化偏置值\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "# 卷积层\n",
    "def conv2d(x,W):\n",
    "    # x input tensor of shape '[batch, in_height, in_width, in_channels]'\n",
    "    # W filter/kernel tensor of shape[filter_heght, filter_width, in_channels, out_channels]\n",
    "    # 'strides[0] = strides[3] = 1'  strides[1]表示x方向的步长, strides[2]表示y方向的步长\n",
    "    # padding: A 'string' from: \"SAME\" \"VALID\"\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding=\"SAME\")\n",
    "\n",
    "# 池化层\n",
    "def max_pool_2X2(x):\n",
    "    # ksize[1,x,y,1] 表示窗口的大小 ksize[0] 和ksize[3] 设置为1 ,x 和 y 是池化的窗口大小\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "# 定义两个placeholder\n",
    "x = tf.placeholder(tf.float32, [None, 784])  # 28X28\n",
    "y = tf.placeholder(tf.float32, [None, 10]) \n",
    "\n",
    "# 改变x的格式转化为4D的向量 [batch, in_height, in_width, in_channels]\n",
    "# 将原来图片784组成的一维复原为28X28的二维\n",
    "# 最后一个参数1代表是黑白的图片 ，彩色图片此值为3\n",
    "x_image = tf.reshape(x, [-1, 28, 28, 1])\n",
    "\n",
    "# 初始化第一个卷积层的权值和偏置\n",
    "W_conv1 = weight_variable([5, 5, 1, 32])  # 5X5的采样窗口，32个卷积核从1个平面抽取特征\n",
    "b_conv1 = bias_variable([32])  # 每一个卷积核一个偏置值\n",
    "\n",
    "# 把x_image和权值向量进行卷积再加上偏置值，然后用Rule激活函数\n",
    "h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
    "# 进行max pooling\n",
    "h_pool1 = max_pool_2X2(h_conv1) \n",
    "\n",
    "# 初始化第二个卷积层的权值和偏置\n",
    "W_conv2 = weight_variable([5, 5, 32, 64])  # 5X5的采样窗口，64个卷积核从32个平面抽取特征\n",
    "b_conv2 = bias_variable([64])  # 每一个卷积核一个偏置值\n",
    "\n",
    "# 把h_pool1和权值向量进行卷积，再加上偏置值，然后用Rule激活函数\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "# 进行max pooling\n",
    "h_pool2 = max_pool_2X2(h_conv2)\n",
    "\n",
    "# 最开始的28X28的图片经过第一次卷积后还是28X28，经过第一次池化后变成14X14\n",
    "# 第二次卷积后是14X14，第二次池化后是7X7\n",
    "# 经过上述的一次操作，最后得到64张7X7的平面\n",
    "\n",
    "# 初始化第一个全连接层的权值\n",
    "W_fc1 = weight_variable([7*7*64, 1024])  # 经过所有的卷积层之后一共有64*7*7个神经元(输入)，全连接层一共设置1024个神经元\n",
    "b_fc1 = bias_variable([1024])\n",
    "\n",
    "# 把卷积层最后输出的64张7*7的图片扁平化为1维向量，用于全连接层的输入\n",
    "# -1 跟 None 一样，代表任意值 ， 最终在本例中实际最后填入的值是100，因为1个批次100个样本\n",
    "h_pool2_flat = tf.reshape(h_pool2, [-1,7*7*64])\n",
    "\n",
    "# 第一个全连接层的输出\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n",
    "\n",
    "# 用keep_prob来表示神经元的输出概率(防止过拟合)\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "\n",
    "# 初始化第二个全连接层(输出层)\n",
    "W_fc2 = weight_variable([1024, 10])  # 经过第一个隐藏层后，一共有1024个，最终的输出是10个，所以隐藏层2设置为1024X10\n",
    "b_fc2 = bias_variable([10])\n",
    "\n",
    "# 计算最后的输出\n",
    "prediction = tf.nn.softmax(tf.matmul(h_fc1_drop, W_fc2) + b_fc2)\n",
    "\n",
    "# 代价函数使用交叉熵\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=y, logits=prediction))\n",
    "\n",
    "# 梯度下降采用Adam\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(loss)\n",
    "\n",
    "# 将softmax输出的结果解析出来，求得其预测的实际值\n",
    "# 然后与标签值进行对比，存入一个全是布尔型变量的列表中\n",
    "correct_prediction = tf.equal(tf.arg_max(prediction, 1), tf.arg_max(y, 1))\n",
    "\n",
    "# 最后将上面的布尔型变量列表转化为 0-1 列表，求得其平均值即是其准确率\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for epoch in range(21):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        sess.run(train_step, feed_dict={x:batch_xs, y:batch_ys, keep_prob:0.7})\n",
    "    acc = sees.run(accuracy, feed_dict={x:mnist.test.images, y:mnist.test.labels, keep_prob:1.0})\n",
    "    print(\"第\"+str(epoch)+\"次迭代的准确率为: \"+str(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3-7for learn",
   "language": "python",
   "name": "py3-7forlearn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
